# ðŸš€ AWS Performance Optimization Configuration
# This file contains all the optimization settings for maximum performance

# REGION CONFIGURATION
aws_region: "us-east-1"
availability_zones:
  - "us-east-1a"
  - "us-east-1b"
  - "us-east-1c"

# INSTANCE OPTIMIZATION
instance_optimization:
  # Kernel Parameters
  kernel_tuning:
    vm_swappiness: 1
    vm_dirty_ratio: 15
    vm_dirty_background_ratio: 5
    net_core_rmem_max: 134217728
    net_core_wmem_max: 134217728
    net_ipv4_tcp_congestion_control: "bbr"
    
  # GPU Optimization (for ML instances)
  gpu_tuning:
    enable_persistent_mode: true
    memory_clock: 1215
    graphics_clock: 1410
    disable_auto_boost: true
    gpu_memory_fraction: 0.95
    
  # Memory Optimization
  memory_tuning:
    enable_huge_pages: true
    transparent_huge_pages: "madvise"
    swappiness: 1

# STORAGE OPTIMIZATION
storage_optimization:
  # EBS Volume Types
  ebs_volumes:
    gp3:
      iops: 16000
      throughput: 1000
      cost_per_gb_month: 0.08
    io2_block_express:
      iops: 256000
      throughput: 4000
      cost_per_gb_month: 0.25
      
  # S3 Optimization
  s3_optimization:
    transfer_acceleration: true
    intelligent_tiering: true
    lifecycle_policies:
      - transition_days: 30
        storage_class: "glacier_instant_retrieval"
        
  # Local NVMe (if available)
  local_nvme:
    raid_configuration: "raid0"
    enable_trim: true

# NETWORK OPTIMIZATION
network_optimization:
  # TCP Tuning
  tcp_tuning:
    congestion_control: "bbr"
    window_scaling: true
    timestamps: true
    sack: true
    
  # Network Buffer Sizes
  buffer_sizes:
    rmem_default: 262144
    wmem_default: 262144
    rmem_max: 16777216
    wmem_max: 16777216
    
  # Placement Groups
  placement_groups:
    - name: "ml_training_cluster"
      strategy: "cluster"
      instances: []
    - name: "inference_cluster"
      strategy: "partition"
      instances: []

# AUTO SCALING CONFIGURATION
auto_scaling:
  # Training Auto Scaling
  training:
    min_capacity: 1
    max_capacity: 10
    target_cpu_utilization: 70
    target_gpu_utilization: 85
    scale_up_cooldown: 300
    scale_down_cooldown: 600
    
  # Inference Auto Scaling
  inference:
    min_capacity: 2
    max_capacity: 20
    target_cpu_utilization: 60
    target_latency: 100  # milliseconds
    scale_up_cooldown: 180
    scale_down_cooldown: 300

# COST OPTIMIZATION
cost_optimization:
  # Spot Instances
  spot_instances:
    enabled: true
    max_price: "on-demand"
    interruption_behavior: "terminate"
    spot_fleet:
      target_capacity: 8
      allocation_strategy: "lowest-price"
      
  # Reserved Instances
  reserved_instances:
    term: "3_year"
    payment_option: "all_upfront"
    savings: 0.60
    
  # Savings Plans
  savings_plans:
    type: "compute"
    commitment: "3_year"
    hourly_commitment: 20
    savings: 0.72

# MONITORING & ALERTING
monitoring:
  # CloudWatch Metrics
  cloudwatch:
    metrics_interval: 10  # seconds
    log_retention_days: 30
    custom_metrics:
      - gpu_utilization
      - gpu_memory_utilization
      - training_throughput
      - inference_latency
      - cost_per_hour
      
  # Alarms
  alarms:
    cpu_utilization:
      threshold: 80
      period: 300
      actions: ["scale_out"]
    gpu_utilization:
      threshold: 90
      period: 300
      actions: ["scale_out"]
    cost_alert:
      threshold: 100  # dollars per hour
      period: 3600
      actions: ["notify", "scale_down"]

# ML FRAMEWORK OPTIMIZATION
ml_optimization:
  # TensorFlow
  tensorflow:
    xla: true
    mixed_precision: true
    num_parallel_calls: 8
    prefetch_buffer_size: 4
    
  # PyTorch
  pytorch:
    compile_mode: "reduce-overhead"
    backend: "inductor"
    mixed_precision: true
    num_workers: 8
    prefetch_factor: 4
    
  # vLLM
  vllm:
    tensor_parallel_size: 8
    max_model_len: 8192
    gpu_memory_utilization: 0.95
    enable_prefix_caching: true

# SECURITY & COMPLIANCE
security:
  # IAM Roles
  iam_roles:
    - name: "MLTrainingRole"
      policies:
        - "AmazonS3ReadWriteAccess"
        - "CloudWatchLogsFullAccess"
        - "EC2InstanceConnect"
        - "AutoScalingFullAccess"
        
  # Security Groups
  security_groups:
    - name: "MLTrainingSG"
      rules:
        - protocol: "tcp"
          port: 22
          source: "0.0.0.0/0"
        - protocol: "tcp"
          port: 8000
          source: "0.0.0.0/0"
        - protocol: "tcp"
          port: 443
          source: "0.0.0.0/0"
          
  # Encryption
  encryption:
    ebs_encryption: true
    s3_encryption: true
    transit_encryption: true

# DEPLOYMENT CONFIGURATION
deployment:
  # Infrastructure as Code
  infrastructure:
    terraform: false
    cloudformation: true
    cdk: false
    
  # CI/CD Pipeline
  ci_cd:
    github_actions: true
    codebuild: false
    codepipeline: false
    
  # Container Registry
  container_registry:
    ecr: true
    docker_hub: false
    
  # Load Balancer
  load_balancer:
    type: "application"
    scheme: "internet-facing"
    idle_timeout: 60
    connection_draining_timeout: 300
