{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSeek-R1 Training and Fine-tuning\n",
        "\n",
        "This notebook provides comprehensive training and fine-tuning capabilities for DeepSeek-R1 models.\n",
        "\n",
        "## Features:\n",
        "- Download and configure DeepSeek-R1 models\n",
        "- Create reasoning datasets for fine-tuning\n",
        "- Fine-tune DeepSeek-R1 distilled models\n",
        "- Integrate with brain simulation framework\n",
        "- Monitor training progress and performance\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional\n",
        "from pathlib import Path\n",
        "\n",
        "# Transformers and training libraries\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset, load_dataset\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# Add project paths\n",
        "sys.path.append('../../src')\n",
        "sys.path.append('../../database')\n",
        "\n",
        "# Configure matplotlib\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "print(\"ðŸ§  DeepSeek-R1 Training Environment\")\n",
        "print(f\"ðŸ”§ PyTorch version: {torch.__version__}\")\n",
        "print(f\"ðŸš€ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ðŸ“± GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
