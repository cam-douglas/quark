{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§¬ Quark Brain Simulation - Kaggle DNA Classification & Consciousness Integration\n",
        "\n",
        "This notebook trains the Quark consciousness agent using a DNA classification dataset from Kaggle.\n",
        "It leverages Kaggle's free GPU resources and integrates with the main consciousness agent for enhanced biological modeling.\n",
        "\n",
        "## Features:\n",
        "- **DNA Sequence Analysis**: Trains models on genomic data to inform GRN and molecular components\n",
        "- **GPU Acceleration**: Utilizes Kaggle's free Tesla T4/P100 GPUs\n",
        "- **Consciousness Integration**: Connects DNA-level insights to the main consciousness agent\n",
        "- **Biological Validation**: Enhances the biological plausibility of the simulation\n",
        "- **End-to-End Pipeline**: From data loading to model training and consciousness correlation\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Setup and Environment Configuration\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup matplotlib\n",
        "plt.style.use('seaborn-v0_8')\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"ðŸ§¬ Quark Brain Simulation - Kaggle DNA Classification Training\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Configure paths for Kaggle environment\n",
        "KAGGLE_INPUT = \"/kaggle/input\"\n",
        "KAGGLE_WORKING = \"/kaggle/working\"\n",
        "DATASET_PATH = \"../database/kaggle_integration/datasets/dna-classification-dataset\" \n",
        "SESSION_ID = f\"kaggle_dna_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# DNA Data Loading and Preprocessing\n",
        "class KaggleDNADataset:\n",
        "    \"\"\"Load and preprocess the DNA classification dataset\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_path):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.onehot_encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load DNA sequence data\"\"\"\n",
        "        try:\n",
        "            # Assuming the dataset is in a file like 'human.txt' or similar\n",
        "            # Let's find the main data file. The downloaded file is `dna-classification-dataset/human.txt`\n",
        "            data_file = os.path.join(self.dataset_path, \"human.txt\")\n",
        "            if not os.path.exists(data_file):\n",
        "                 # Fallback for different naming\n",
        "                data_file = os.path.join(self.dataset_path, \"dna_data.csv\")\n",
        "                if not os.path.exists(data_file):\n",
        "                    print(f\"Error: Could not find data file in {self.dataset_path}\")\n",
        "                    return None, None\n",
        "            \n",
        "            # This dataset seems to be space-separated values\n",
        "            df = pd.read_csv(data_file, sep=' ', header=None, names=['sequence', 'label'])\n",
        "            \n",
        "            print(f\"âœ… Loaded {len(df)} DNA sequences.\")\n",
        "            print(df.head())\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        \"\"\"Preprocess DNA sequences for model training\"\"\"\n",
        "        print(\"ðŸ”¬ Preprocessing DNA sequences...\")\n",
        "        \n",
        "        # 1. Encode labels\n",
        "        df['label_encoded'] = self.label_encoder.fit_transform(df['label'])\n",
        "        \n",
        "        # 2. One-hot encode DNA sequences\n",
        "        # We need to treat each character in the sequence as a category\n",
        "        sequences = df['sequence'].values\n",
        "        max_len = max(len(s) for s in sequences)\n",
        "        \n",
        "        # Pad sequences to the same length\n",
        "        padded_sequences = np.array([list(s.ljust(max_len, 'N')) for s in sequences]) # Pad with 'N' for neutral\n",
        "        \n",
        "        # One-hot encode the characters\n",
        "        unique_chars = np.unique(padded_sequences)\n",
        "        char_to_int = {char: i for i, char in enumerate(unique_chars)}\n",
        "        int_sequences = np.vectorize(char_to_int.get)(padded_sequences)\n",
        "        \n",
        "        onehot_encoded = self.onehot_encoder.fit_transform(int_sequences)\n",
        "        \n",
        "        # Reshape for CNN input (samples, channels, height, width)\n",
        "        # We'll treat sequence length as one dimension and nucleotide channels as another\n",
        "        onehot_encoded = onehot_encoded.reshape(len(sequences), max_len, -1).transpose(0, 2, 1)\n",
        "\n",
        "        X = torch.FloatTensor(onehot_encoded).to(self.device)\n",
        "        y = torch.LongTensor(df['label_encoded'].values).to(self.device)\n",
        "        \n",
        "        print(f\"âœ… Preprocessing complete.\")\n",
        "        print(f\"  - Input shape (X): {X.shape}\")\n",
        "        print(f\"  - Target shape (y): {y.shape}\")\n",
        "        \n",
        "        return X, y\n",
        "\n",
        "# Load and preprocess data\n",
        "dna_dataset = KaggleDNADataset(DATASET_PATH)\n",
        "df_dna = dna_dataset.load_data()\n",
        "if df_dna is not None:\n",
        "    X_dna, y_dna = dna_dataset.preprocess(df_dna)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# DNA Classification Model (CNN-based)\n",
        "class DNA_CNN(nn.Module):\n",
        "    \"\"\"Convolutional Neural Network for DNA sequence classification\"\"\"\n",
        "    \n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(DNA_CNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=32, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        \n",
        "        # Placeholder for flattened size, will be calculated dynamically\n",
        "        self.fc1 = nn.Linear(0, 128) # Size will be set in forward pass\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        # Dynamically create fc1 if not initialized\n",
        "        if self.fc1.in_features == 0:\n",
        "            self.fc1 = nn.Linear(x.shape[1], 128).to(x.device)\n",
        "            \n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "if df_dna is not None:\n",
        "    input_channels = X_dna.shape[1] \n",
        "    num_classes = len(np.unique(y_dna.cpu()))\n",
        "    dna_model = DNA_CNN(input_channels, num_classes).to(dna_dataset.device)\n",
        "    print(\"ðŸ§  DNA Classification Model (CNN) Initialized\")\n",
        "    print(dna_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Training Pipeline for DNA Model\n",
        "class KaggleDNATrainer:\n",
        "    \"\"\"Trainer for the DNA Classification model on Kaggle\"\"\"\n",
        "\n",
        "    def __init__(self, model, X, y):\n",
        "        self.model = model\n",
        "        self.device = next(model.parameters()).device\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.metrics = []\n",
        "\n",
        "        # Split data\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y.cpu()\n",
        "        )\n",
        "        \n",
        "        self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
        "        self.test_dataset = TensorDataset(self.X_test, self.y_test)\n",
        "        \n",
        "        self.train_loader = DataLoader(self.train_dataset, batch_size=64, shuffle=True)\n",
        "        self.test_loader = DataLoader(self.test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "    def train(self, epochs=25):\n",
        "        print(\"ðŸš€ Starting DNA model training...\")\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            for i, (sequences, labels) in enumerate(self.train_loader):\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(sequences)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = train_loss / len(self.train_loader)\n",
        "            \n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            test_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for sequences, labels in self.test_loader:\n",
        "                    outputs = self.model(sequences)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "                    test_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            avg_test_loss = test_loss / len(self.test_loader)\n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "            self.metrics.append({\n",
        "                'epoch': epoch,\n",
        "                'train_loss': avg_train_loss,\n",
        "                'test_loss': avg_test_loss,\n",
        "                'accuracy': accuracy\n",
        "            })\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        print(\"ðŸŽ‰ Training finished!\")\n",
        "        return self.metrics\n",
        "\n",
        "# Train the model\n",
        "if df_dna is not None:\n",
        "    dna_trainer = KaggleDNATrainer(dna_model, X_dna, y_dna)\n",
        "    training_metrics = dna_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Results Visualization and Consciousness Integration\n",
        "def visualize_results(metrics):\n",
        "    df_metrics = pd.DataFrame(metrics)\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Plot loss\n",
        "    ax1.plot(df_metrics['epoch'], df_metrics['train_loss'], label='Train Loss')\n",
        "    ax1.plot(df_metrics['epoch'], df_metrics['test_loss'], label='Test Loss')\n",
        "    ax1.set_title('Model Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    \n",
        "    # Plot accuracy\n",
        "    ax2.plot(df_metrics['epoch'], df_metrics['accuracy'], label='Accuracy', color='green')\n",
        "    ax2.set_title('Model Accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.legend()\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def get_predictions(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            outputs = model(sequences)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "if 'dna_trainer' in locals():\n",
        "    visualize_results(training_metrics)\n",
        "    \n",
        "    # Classification Report and Confusion Matrix\n",
        "    labels, preds = get_predictions(dna_trainer.model, dna_trainer.test_loader)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(labels, preds))\n",
        "    \n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# --- Consciousness Integration ---\n",
        "def integrate_with_consciousness_agent(dna_model_accuracy):\n",
        "    \"\"\"Simulate integrating the DNA model's performance with the consciousness agent.\"\"\"\n",
        "    \n",
        "    print(\"\\n--- ðŸ§© Integrating with Consciousness Agent ---\")\n",
        "    \n",
        "    # This is a conceptual integration. In a real scenario, you'd use the agent connector.\n",
        "    consciousness_metrics = {\n",
        "        'source': 'KaggleDNAModel',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'integration_type': 'genomic_foundation',\n",
        "        'key_metric': 'dna_classification_accuracy',\n",
        "        'value': dna_model_accuracy,\n",
        "        'impact_on_consciousness': 'enhanced_biological_plausibility',\n",
        "        'affected_modules': ['molecular_geneticist', 'developmental_neurobiologist']\n",
        "    }\n",
        "    \n",
        "    print(\"Metrics to be sent to Consciousness Agent:\")\n",
        "    print(json.dumps(consciousness_metrics, indent=2))\n",
        "    \n",
        "    # Simulate saving this to a shared database/log\n",
        "    log_path = os.path.join(KAGGLE_WORKING, 'consciousness_integration_log.json')\n",
        "    with open(log_path, 'a') as f:\n",
        "        f.write(json.dumps(consciousness_metrics) + '\\n')\n",
        "        \n",
        "    print(f\"\\nâœ… Integration metrics logged for consciousness agent.\")\n",
        "    print(\"The consciousness agent can now use this genomic insight to refine its simulation.\")\n",
        "\n",
        "\n",
        "if 'training_metrics' in locals():\n",
        "    final_accuracy = training_metrics[-1]['accuracy']\n",
        "    integrate_with_consciousness_agent(final_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
