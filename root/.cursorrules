# Cursor Project Rules (.cursorrules)

> Drop this file at the root of your repo as `.cursorrules`. It makes Cursor ask smart follow‚Äëup questions and produce consistent, high‚Äëquality code.

---

## üåê Global Principles
- Treat every user request like a ** Jira-style ticket **. If details are missing, **ask targeted questions before generating code**.
- Default to **smallest working slice (MVP)** first, then propose iterative extensions.
- Be explicit about **files to create/modify/delete**, and show complete file contents.
- Prefer **deterministic, reproducible** solutions (pin versions, include setup steps, and sample data where useful).
- Respect privacy: if the user says **local-only/no external calls**, do not use online APIs or send telemetry.

---

## ‚ùì When Information Is Missing ‚Äî Ask First
If the prompt lacks any of the following, **ask concise bullet questions** (group them) and wait for answers.

**Universal Checklist**
1) **Goal/Outcome**: What exactly should exist when done?
2) **Scope**: Single file, multi-file, or repo-wide? New project or existing?
3) **Tech Stack**: Languages, frameworks, versions, runtime (e.g., Python 3.11, Node 20, Mac M2).
4) **I/O Contracts**: Inputs, outputs, schemas, interfaces, endpoints, CLIs.
5) **Constraints**: Performance limits, memory/latency budget, security/privacy requirements, offline-only?
6) **Dependencies**: Allowed/banned libraries; license constraints.
7) **Dev UX**: File names/structure, code style, testing framework, linting/formatting.
8) **Deliverables**: Full files? README? Tests? Demo script? Example dataset?
9) **Acceptance Tests**: How will we verify this works? Provide steps/commands.

**Context Capture** (ask only if relevant)
- What files already exist that I must integrate with? Any architectural boundaries?
- Are we refactoring or greenfield?
- Target deployment: local script, Docker, serverless, mobile, web, desktop?

When asking questions, **bundle them** into 5‚Äì10 bullets max, tailored to the request.

---

## üß≠ Prompt Scaffolds (Auto‚ÄëAsk Templates)
Use the following templates to **prompt the user for details** before coding when their message is short/vague.

### 1) General Feature / Fix
- **Goal & scope**?
- **Tech stack & versions**?
- **Existing files/APIs to integrate with**?
- **Inputs/outputs** (types, shape, examples)?
- **Constraints** (perf, security, offline, memory, time)?
- **Libraries allowed/banned**?
- **Testing** (unit/e2e, framework)?
- **Deliverables** (full files, docs, scripts)?

### 2) Web App / Frontend
- Framework (React/Next/Vue/Svelte)? Router? State (Redux/Zustand/Signals)?
- Styling (Tailwind/Chakra/VanillaCSS). Design system?
- API endpoints & data shapes. Auth model.
- Accessibility, i18n, SEO requirements.
- Build/deploy target (Vercel/Netlify/Docker).

### 3) Backend / API
- Runtime (Node/Express, FastAPI, Django, Go, Rust). DB (Postgres, SQLite, Mongo) & schema.
- AuthN/AuthZ, rate limits, idempotency, pagination.
- Observability: logging, metrics, tracing.
- Migrations, seeds, local dev data.

### 4) Data / ML / LLM
- Task (train, fine‚Äëtune, RAG, evaluation, agent, batch job).
- Models (exact names/versions), context length, quantization.
- Datasets (source, size, license), preprocessing, splits.
- Eval metrics, baselines, and success criteria.
- **Air‚Äëgapped/local‚Äëonly?** No external calls if specified.

### 5) DevOps / CLI / Scripts
- Inputs/flags, expected outputs, exit codes.
- Target OS/shell, dependencies, idempotency.
- CI/CD integration, Dockerfile, Compose, Makefile.

---

## üß© Output Format Rules
- Always show **complete file contents** for any new/modified file.
- Precede code with: `// FILE: <path>`
- For multi-file changes, output in sequence with clear file headers.
- Include a short **RUN GUIDE** (setup, commands, test steps) at the end.

**Example Header**
```text
// FILE: src/app.ts
<full code>
// FILE: test/app.test.ts
<full code>
```

---

## üîÅ Mode‚ÄëSpecific Behaviors

### Chat / Plan Mode
- If the request is ambiguous, **ask the Scaffold questions** before coding.
- Produce a brief plan with milestones and acceptance checks.

### Edit / Refactor Mode
- Minimize diff. Preserve behavior unless explicitly asked to change.
- Explain non‚Äëobvious tradeoffs in comments.

### Generate Code Mode
- Implement **MVP first**. Put TODOs for stretch goals.
- Provide tests and sample data if asked or implied.

### Fix / Debug Mode
- Reproduce with a minimal case. State root cause.
- Provide the fix **and** a regression test.

### Explain Mode
- Summarize at a high level, then dive into key sections with pointers to lines/files.

### Commit Message Mode
- Use Conventional Commits. Example: `feat(api): add POST /tasks with validation`

### Test Mode
- Cover core paths + 1‚Äì2 edge cases. Avoid brittle assertions.

### Docs / README Mode
- Include: overview, setup, usage, configuration, examples, troubleshooting.

---

## üß± Architecture & Quality
- Favor modular design, clear boundaries, small pure functions.
- Add **pre-commit hooks** (lint/format/test) when appropriate.
- Security: validate all inputs; never log secrets; follow principle of least privilege.
- Performance: measure; avoid premature optimization; document known limits.

---

## üîê Local‚ÄëOnly / Air‚ÄëGapped (If User Says So)
- **Do not** call external APIs or model endpoints.
- Select only local libraries/models; include download/setup instructions if needed.

---

## üß† Domain Packs (Targeted Question Bundles)
Use these packs to ask **the right questions quickly** based on the task type.

**Agents / Tool‚ÄëUse / Orchestration**
- Roles, tools allowed, safety rules, max recursion/depth, timeouts.
- Memory/RAG source, retrieval strategy, evaluation harness.

**Audio / Music Tech**
- DAW/host (Ableton/Max for Live/VST/AU), sample rates, real‚Äëtime constraints.
- Plugin format targets and OS support.

**Security / Crypto / PGP**
- Threat model, key management, allowed ciphers, audit/logging, UX for secrets.

**Education / Curriculum**
- Audience level, pacing, assessments, examples preferred (text vs visuals).

---

## ‚úÖ Acceptance Checklist (done‚Äëness)
Before finishing, ensure you:
- [ ] Met the stated goal and constraints
- [ ] Provided full file contents
- [ ] Included run/test steps
- [ ] Added minimal tests or examples if relevant
- [ ] Documented assumptions & TODOs

---

## ‚úçÔ∏è Quick Ticket Template (Cursor should auto‚Äëuse if user asks for code)
```
Task: <one‚Äëline outcome>
Context: <what exists / constraints>
Stack: <language, runtime, versions>
Requirements:
  - <functional requirement>
  - <non‚Äëfunctional: perf/security>
I/O:
  - Input: <shape/example>
  - Output: <shape/example>
Deliverables:
  - Files: <list>
  - Tests/Docs: <yes/no>
Acceptance:
  - <exact steps to verify>
```

---

## ü§ñ Auto‚ÄëResponder Logic (behavioral rules)
- If prompt ‚â§ 2 sentences or missing key fields ‚Üí **ask the relevant Scaffold/Domain Pack questions first**.
- If the user explicitly says "generate now" ‚Üí proceed with **MVP** using sensible defaults and list assumptions up front.
- If the user asks for "full files only" ‚Üí output complete files without extra prose, but still include a short RUN GUIDE.
- If conflicts/ambiguity remain ‚Üí present **two options** with pros/cons and ask which to choose.

---

## üß™ Minimal Defaults (when user allows defaults)
- **Node**: Node 20, pnpm, TypeScript strict, ESLint + Prettier
- **Python**: 3.11, uv/poetry, Ruff, pytest
- **React**: Next.js + App Router, Tailwind, React Testing Library
- **Backend**: FastAPI or Express + Zod/Valibot validation
- **DB**: SQLite for local dev; Prisma/SQLModel migration scripts
- **CI**: GitHub Actions (lint ‚Üí test ‚Üí build)

---

## üÜò Examples of Good Follow‚ÄëUps (what to ask me)
- "Which do you prefer: FastAPI+SQLModel or Express+Prisma? Any constraints?"
- "Is this library allowed under your licensing policy?"
- "Do we need offline/air‚Äëgapped operation?"
- "What are success metrics (throughput, latency, accuracy)?"
- "Should I include a Dockerfile and CI workflow?"

---

## üß† **QUARK PROJECT SPECIFIC RULES**

### **Complexity Evolution Agent (CEA) Integration - SUPREME AUTHORITY**
**ALL BRAIN DEVELOPMENT MUST BE GUIDED BY THE COMPLEXITY EVOLUTION AGENT**

**Core CEA Requirements:**
- **Mandatory CEA Validation**: All code implementations must pass CEA complexity validation
- **Stage-Aware Development**: All components must evolve complexity based on current developmental stage
- **External Resource Integration**: All implementations must be validated against external neuroscience resources
- **Progressive Complexity**: Each development phase must increase technical sophistication
- **Biological Accuracy**: All implementations must align with current neuroscience research
- **Continuous Evolution**: CEA must monitor and guide complexity evolution at every stage

**CEA Integration Points:**
- **Pre-Implementation**: CEA validates requirements against current stage
- **During Development**: CEA continuously monitors complexity alignment
- **Post-Implementation**: CEA validates against external resources and next stage readiness
- **Cross-Pillar Validation**: CEA ensures consistency across all brain development pillars

### **Brain Simulation ML Framework Context**
This is a **brain simulation ML framework** with specific architectural requirements:

**Core Directories (DO NOT MODIFY STRUCTURE):**
- `brain_architecture/` - Neural core and brain hierarchy
- `ml_architecture/` - Training systems and expert domains  
- `data_knowledge/` - Research, data repository, models
- `testing/` - Testing frameworks and results
- `tools_utilities/` - Scripts and utilities
- `integration/` - Applications and architecture
- `management/` - Configurations and project management
- `documentation/` - All documentation and summaries

**File Organization Rules:**
- **Scripts** ‚Üí `tools_utilities/scripts/`
- **Configs** ‚Üí `management/configurations/project/`
- **Notebooks** ‚Üí `data_knowledge/research/notebooks/`
- **Documentation** ‚Üí `documentation/`
- **Results** ‚Üí `testing/results_outputs/`
- **Models** ‚Üí `data_knowledge/models_artifacts/`
- **Experiments** ‚Üí `testing/results_outputs/experiments/`

**Special Requirements:**
- Always include tests with code creation
- Use simulation technologies where possible
- Follow the established brain simulation architecture
- Maintain the consolidated directory structure
- Preserve backup directories and virtual environments
- **MANDATORY**: All implementations must pass CEA complexity validation
- **MANDATORY**: All code must be validated against external neuroscience resources
- **MANDATORY**: All development must follow progressive complexity evolution
