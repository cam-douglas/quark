#!/usr/bin/env python3
"""Test S3 Streaming Capabilities
Demonstrates streaming models and datasets directly from S3

Integration: Indirect integration via QuarkDriver and AutonomousAgent; orchestrates simulator runs.
Rationale: State system validates, plans, and triggers actions that the simulator executes.
"""

import sys
from pathlib import Path

# Add the quark_state_system to path
sys.path.append(str(Path(__file__).parent))

from s3_streaming_manager import S3StreamingManager

def test_all_streaming_capabilities():
    """Test streaming all file types from S3"""
    print("ğŸŒŠ Testing S3 Streaming Capabilities")
    print("=" * 40)

    streaming_manager = S3StreamingManager()

    # Get current S3 inventory
    inventory = streaming_manager.get_s3_inventory()
    print(f"ğŸ“¦ S3 Contents: {inventory['total_objects']} objects ({inventory['total_size_mb']}MB)")

    results = {
        'pytorch_model': False,
        'numpy_data': False,
        'hdf5_data': False,
        'pytorch_dataset': False
    }

    # 1. Test PyTorch Model Streaming
    print("\nğŸ§  Testing PyTorch Model Streaming...")
    try:
        with streaming_manager.stream_model_from_s3('models/neural/neural_dynamics_model') as model:
            if model is not None:
                print("âœ… PyTorch model streamed successfully!")
                print(f"   Model type: {type(model)}")
                if isinstance(model, dict):
                    print(f"   Keys: {list(model.keys())}")
                results['pytorch_model'] = True
            else:
                print("âŒ Failed to stream PyTorch model")
    except Exception as e:
        print(f"âŒ PyTorch model streaming error: {e}")

    # 2. Test NumPy Data Streaming
    print("\nğŸ“Š Testing NumPy Data Streaming...")
    try:
        with streaming_manager.stream_numpy_from_s3('datasets/cognitive/cognitive_benchmarks') as data:
            if data is not None:
                print("âœ… NumPy data streamed successfully!")
                print(f"   Shape: {data.shape}")
                print(f"   Data type: {data.dtype}")
                print(f"   Memory usage: {data.nbytes / 1024:.1f}KB")
                results['numpy_data'] = True
            else:
                print("âŒ Failed to stream NumPy data")
    except Exception as e:
        print(f"âŒ NumPy streaming error: {e}")

    # 3. Test HDF5 Data Streaming
    print("\nğŸ§¬ Testing HDF5 Data Streaming...")
    try:
        with streaming_manager.stream_hdf5_from_s3('datasets/brain/brain_connectivity_data') as h5_file:
            if h5_file is not None:
                print("âœ… HDF5 data streamed successfully!")
                print(f"   Keys: {list(h5_file.keys())}")
                if 'connectivity_matrix' in h5_file:
                    conn_matrix = h5_file['connectivity_matrix'][:]
                    print(f"   Connectivity matrix shape: {conn_matrix.shape}")
                results['hdf5_data'] = True
            else:
                print("âŒ Failed to stream HDF5 data")
    except Exception as e:
        print(f"âŒ HDF5 streaming error: {e}")

    # 4. Test PyTorch Dataset Streaming
    print("\nğŸ“š Testing PyTorch Dataset Streaming...")
    try:
        with streaming_manager.stream_model_from_s3('datasets/neural/neural_training_data') as dataset:
            if dataset is not None:
                print("âœ… PyTorch dataset streamed successfully!")
                print(f"   Keys: {list(dataset.keys()) if isinstance(dataset, dict) else 'Not a dict'}")
                if isinstance(dataset, dict):
                    if 'inputs' in dataset:
                        print(f"   Input shape: {dataset['inputs'].shape}")
                    if 'targets' in dataset:
                        print(f"   Target shape: {dataset['targets'].shape}")
                results['pytorch_dataset'] = True
            else:
                print("âŒ Failed to stream PyTorch dataset")
    except Exception as e:
        print(f"âŒ PyTorch dataset streaming error: {e}")

    # Summary
    print("\nğŸ“‹ Streaming Test Summary:")
    success_count = sum(results.values())
    total_tests = len(results)

    for test_name, success in results.items():
        icon = "âœ…" if success else "âŒ"
        print(f"   {icon} {test_name}: {'PASSED' if success else 'FAILED'}")

    print(f"\nğŸ¯ Overall: {success_count}/{total_tests} tests passed")

    if success_count == total_tests:
        print("ğŸ‰ All streaming capabilities working perfectly!")
    else:
        print("âš ï¸ Some streaming tests failed - check logs above")

    return results

def demonstrate_memory_efficiency():
    """Demonstrate memory efficiency of streaming vs downloading"""
    print("\nğŸ’¾ Memory Efficiency Demonstration")
    print("=" * 40)

    streaming_manager = S3StreamingManager()

    print("ğŸ§  Streaming models/datasets uses minimal local memory:")
    print("   â€¢ PyTorch models: Loaded directly into memory")
    print("   â€¢ NumPy arrays: Streamed without disk cache")
    print("   â€¢ HDF5 files: Temporary file, auto-cleaned")
    print("   â€¢ Large datasets: Only needed portions loaded")
    print()
    print("ğŸ“ˆ Benefits:")
    print("   âœ… No local storage consumed")
    print("   âœ… Instant access to models")
    print("   âœ… Memory usage = only what you're actively using")
    print("   âœ… Perfect for 200GB instance storage")

    # Get current inventory
    inventory = streaming_manager.get_s3_inventory()
    print("\nğŸ“Š Current S3 Storage:")
    print(f"   Total files: {inventory['total_objects']}")
    print(f"   Total size: {inventory['total_size_mb']}MB")
    print("   Local storage used: 0MB (streaming only!)")

def show_usage_examples():
    """Show practical usage examples"""
    print("\nğŸ› ï¸ Practical Usage Examples")
    print("=" * 30)

    print("""
# Example 1: Stream a brain model for inference
from s3_streaming_manager import S3StreamingManager

manager = S3StreamingManager()

# Stream model directly from S3
with manager.stream_model_from_s3('models/neural/neural_dynamics_model') as model:
    # Use model for inference
    predictions = model(input_data)

# Example 2: Stream training data in batches
with manager.stream_model_from_s3('datasets/neural/neural_training_data') as dataset:
    inputs = dataset['inputs']
    targets = dataset['targets']
    
    # Train your brain simulation
    for batch in create_batches(inputs, targets):
        train_step(batch)

# Example 3: Stream brain connectivity data
with manager.stream_hdf5_from_s3('datasets/brain/brain_connectivity_data') as h5_file:
    connectivity = h5_file['connectivity_matrix'][:]
    # Use connectivity data for brain simulation
    simulate_brain_network(connectivity)

# Example 4: Stream cognitive benchmarks
with manager.stream_numpy_from_s3('datasets/cognitive/cognitive_benchmarks') as benchmarks:
    # Run cognitive tests
    results = run_cognitive_tests(benchmarks)
""")

def main():
    """Main function"""
    # Test streaming capabilities
    results = test_all_streaming_capabilities()

    # Show memory efficiency
    demonstrate_memory_efficiency()

    # Show usage examples
    show_usage_examples()

    return results

if __name__ == "__main__":
    main()
