#!/usr/bin/env python3
"""
Enhanced Neuro Agent for Exponential Learning System
Orchestrates research, synthesis, and training across all components
"""

import asyncio
import logging
from typing import List, Dict, Any
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class NeuroAgentEnhancer:
    """Enhanced neuro agent that coordinates exponential learning"""
    
    def __init__(self):
        self.learning_system = None
        self.research_hub = None
        self.knowledge_synthesizer = None
        self.cloud_orchestrator = None
        self.active_learning_sessions = []
        
    async def initialize_components(self):
        """Initialize all learning components"""
        from exponential_learning_system import ExponentialLearningSystem
        from research_agents import ResearchAgentHub
        from knowledge_synthesizer import KnowledgeSynthesizer
        from cloud_training_orchestrator import CloudTrainingOrchestrator
        
        self.learning_system = ExponentialLearningSystem()
        self.research_hub = ResearchAgentHub()
        self.knowledge_synthesizer = KnowledgeSynthesizer()
        self.cloud_orchestrator = CloudTrainingOrchestrator()
        
        await self.research_hub.initialize_all()
        
        logger.info("üß† Enhanced Neuro Agent initialized with all components")
    
    async def start_exponential_learning_session(self, topic: str, duration_hours: int = 24):
        """Start an exponential learning session"""
        session_id = f"session_{topic}_{int(datetime.now().timestamp())}"
        
        session = {
            "id": session_id,
            "topic": topic,
            "started_at": datetime.now(),
            "duration_hours": duration_hours,
            "status": "active",
            "learning_cycles": 0,
            "knowledge_gained": 0,
            "research_queries": []
        }
        
        self.active_learning_sessions.append(session)
        
        # Start parallel learning processes
        tasks = [
            self.run_research_loop(session),
            self.run_synthesis_loop(session),
            self.run_training_loop(session)
        ]
        
        await asyncio.gather(*tasks)
        
        return session_id
    
    async def run_research_loop(self, session: Dict[str, Any]):
        """Run continuous research loop"""
        while session["status"] == "active":
            try:
                # Generate research queries
                queries = self.generate_research_queries(session["topic"], session["learning_cycles"])
                
                for query in queries:
                    # Research across all sources
                    results = await self.research_hub.search_all_sources(query)
                    
                    # Store results
                    session["research_queries"].append({
                        "query": query,
                        "results": results,
                        "timestamp": datetime.now()
                    })
                    
                    session["knowledge_gained"] += len(results.get("concepts", []))
                
                session["learning_cycles"] += 1
                await asyncio.sleep(60)  # Research every minute
                
            except Exception as e:
                logger.error(f"‚ùå Research loop error: {e}")
                await asyncio.sleep(300)  # Wait 5 minutes on error
    
    async def run_synthesis_loop(self, session: Dict[str, Any]):
        """Run continuous knowledge synthesis loop"""
        while session["status"] == "active":
            try:
                if len(session["research_queries"]) > 0:
                    # Synthesize recent research
                    recent_queries = session["research_queries"][-10:]  # Last 10 queries
                    
                    for query_data in recent_queries:
                        synthesized = await self.knowledge_synthesizer.synthesize_research_findings(
                            query_data["results"]
                        )
                        
                        # Integrate with learning system
                        if hasattr(self.learning_system, 'integrate_knowledge'):
                            self.learning_system.integrate_knowledge({
                                "new_concepts": synthesized.core_concepts,
                                "connections": [r["source"] + " -> " + r["target"] for r in synthesized.relationships]
                            })
                
                await asyncio.sleep(300)  # Synthesize every 5 minutes
                
            except Exception as e:
                logger.error(f"‚ùå Synthesis loop error: {e}")
                await asyncio.sleep(600)  # Wait 10 minutes on error
    
    async def run_training_loop(self, session: Dict[str, Any]):
        """Run continuous training loop"""
        while session["status"] == "active":
            try:
                # Submit training jobs for new knowledge
                if session["knowledge_gained"] > 100:  # Threshold for training
                    training_config = {
                        "script": f"train_{session['topic']}.py",
                        "hyperparameters": {
                            "learning_rate": 0.001,
                            "batch_size": 32,
                            "epochs": 100
                        },
                        "data_path": f"data/{session['topic']}",
                        "output_path": f"outputs/{session['topic']}"
                    }
                    
                    job_id = await self.cloud_orchestrator.submit_training_job(
                        f"{session['topic']}_{session['learning_cycles']}", 
                        training_config
                    )
                    
                    logger.info(f"üöÄ Submitted training job {job_id} for session {session['id']}")
                    session["knowledge_gained"] = 0  # Reset counter
                
                await asyncio.sleep(1800)  # Check for training every 30 minutes
                
            except Exception as e:
                logger.error(f"‚ùå Training loop error: {e}")
                await asyncio.sleep(1800)  # Wait 30 minutes on error
    
    def generate_research_queries(self, topic: str, cycle: int) -> List[str]:
        """Generate increasingly complex research queries"""
        base_queries = [
            f"{topic} fundamentals",
            f"{topic} advanced concepts",
            f"{topic} recent developments",
            f"{topic} applications",
            f"{topic} challenges and solutions"
        ]
        
        # Add cycle-specific complexity
        complex_queries = [
            f"{topic} quantum computing applications",
            f"{topic} artificial intelligence integration",
            f"{topic} neural network implementations",
            f"{topic} machine learning algorithms",
            f"{topic} deep learning frameworks"
        ]
        
        # Exponential query generation
        all_queries = base_queries + complex_queries
        query_count = min(len(all_queries), 2 ** (cycle % 5))  # Exponential growth with cycle
        
        return all_queries[:query_count]
    
    async def get_learning_status(self) -> Dict[str, Any]:
        """Get current learning status"""
        status = {
            "active_sessions": len(self.active_learning_sessions),
            "total_learning_cycles": sum(s["learning_cycles"] for s in self.active_learning_sessions),
            "total_knowledge_gained": sum(s["knowledge_gained"] for s in self.active_learning_sessions),
            "sessions": self.active_learning_sessions
        }
        
        if self.learning_system:
            status["learning_system"] = {
                "cycles": self.learning_system.learning_cycles,
                "efficiency": self.learning_system.cycle_efficiency,
                "hunger": self.learning_system.knowledge_hunger
            }
        
        if self.cloud_orchestrator:
            status["cloud_training"] = self.cloud_orchestrator.get_all_jobs()
            status["costs"] = self.cloud_orchestrator.get_cost_summary()
        
        return status
    
    async def stop_learning_session(self, session_id: str):
        """Stop a specific learning session"""
        for session in self.active_learning_sessions:
            if session["id"] == session_id:
                session["status"] = "stopped"
                session["ended_at"] = datetime.now()
                logger.info(f"‚èπÔ∏è Stopped learning session {session_id}")
                break
    
    async def cleanup(self):
        """Clean up all components"""
        if self.research_hub:
            await self.research_hub.cleanup_all()
        
        # Stop all active sessions
        for session in self.active_learning_sessions:
            if session["status"] == "active":
                await self.stop_learning_session(session["id"])
        
        logger.info("üßπ Enhanced Neuro Agent cleaned up")

async def main():
    """Test the enhanced neuro agent"""
    agent = NeuroAgentEnhancer()
    
    try:
        await agent.initialize_components()
        
        # Start a learning session
        session_id = await agent.start_exponential_learning_session("quantum_computing", duration_hours=1)
        print(f"üöÄ Started learning session: {session_id}")
        
        # Let it run for a bit
        await asyncio.sleep(30)
        
        # Get status
        status = await agent.get_learning_status()
        print(f"üìä Learning status: {status['active_sessions']} active sessions")
        
        # Stop session
        await agent.stop_learning_session(session_id)
        
    finally:
        await agent.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
