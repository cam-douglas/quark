#!/usr/bin/env python3
"""
Comprehensive Validation System for Anti-Overconfidence
Uses ALL available resources from credentials for intelligent validation
"""

import json
import os
import asyncio
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum
import logging
from pathlib import Path
import requests
from datetime import datetime
import hashlib

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class QueryCategory(Enum):
    """Categories of queries for intelligent source selection"""
    PROTEIN_STRUCTURE = "protein_structure"
    GENOMICS = "genomics"
    NEUROSCIENCE = "neuroscience"
    CHEMISTRY = "chemistry"
    MATERIALS = "materials"
    MACHINE_LEARNING = "machine_learning"
    SCIENTIFIC_LITERATURE = "scientific_literature"
    BIOLOGICAL_SEQUENCE = "biological_sequence"
    CLINICAL = "clinical"
    COMPUTATIONAL = "computational"
    CODE_DOCUMENTATION = "code_documentation"
    GENERAL_AI = "general_ai"
    DATA_SCIENCE = "data_science"
    PHYSICS = "physics"
    MATHEMATICS = "mathematics"

@dataclass
class ValidationSource:
    """Represents a validation source with its capabilities"""
    name: str
    category: List[QueryCategory]
    endpoint: str
    requires_auth: bool
    auth_key: Optional[str] = None
    confidence_weight: float = 1.0
    description: str = ""
    rate_limit: Optional[Dict[str, Any]] = None

class ComprehensiveValidationSystem:
    """
    MANDATORY validation system that uses ALL available resources
    for anti-overconfidence validation
    """
    
    def __init__(self):
        """Initialize with ALL available resources from credentials"""
        self.credentials_path = Path("/Users/camdouglas/quark/data/credentials/all_api_keys.json")
        self.knowledge_path = Path("/Users/camdouglas/quark/data/knowledge/validation_system/open_access_literature_sources.json")
        self.credentials = self._load_credentials()
        self.knowledge_sources = self._load_knowledge_sources()
        self.validation_sources = self._initialize_all_sources()
        self.validation_cache = {}
        self.validation_history = []
        
    def _load_credentials(self) -> Dict[str, Any]:
        """Load ALL API credentials"""
        if not self.credentials_path.exists():
            raise FileNotFoundError(f"‚ùå CRITICAL: Credentials file not found at {self.credentials_path}")
        
        with open(self.credentials_path, 'r') as f:
            creds = json.load(f)
        
        logger.info(f"‚úÖ Loaded credentials for {len(creds.get('services', {}))} services")
        return creds
    
    def _load_knowledge_sources(self) -> Dict[str, Any]:
        """Load additional knowledge sources"""
        if not self.knowledge_path.exists():
            logger.warning(f"‚ö†Ô∏è Knowledge sources file not found at {self.knowledge_path}")
            return {}
        
        with open(self.knowledge_path, 'r') as f:
            sources = json.load(f)
        
        logger.info(f"‚úÖ Loaded {sources['metadata'].get('total_sources', 0)} additional knowledge sources")
        return sources
    
    def _initialize_all_sources(self) -> Dict[str, ValidationSource]:
        """Initialize ALL validation sources from credentials"""
        sources = {}
        
        # Add protein structure sources
        sources['alphafold'] = ValidationSource(
            name="AlphaFold",
            category=[QueryCategory.PROTEIN_STRUCTURE, QueryCategory.BIOLOGICAL_SEQUENCE],
            endpoint=self.credentials['services']['alphafold']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.95,
            description="AI-predicted 3D protein structures"
        )
        
        sources['rcsb_pdb'] = ValidationSource(
            name="RCSB PDB",
            category=[QueryCategory.PROTEIN_STRUCTURE],
            endpoint=self.credentials['services']['rcsb_pdb']['endpoints']['search'],
            requires_auth=False,
            confidence_weight=0.98,
            description="Experimental protein structures"
        )
        
        # Add genomics sources
        sources['ensembl'] = ValidationSource(
            name="Ensembl",
            category=[QueryCategory.GENOMICS],
            endpoint=self.credentials['services']['ensembl']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.95,
            description="Genomics data across vertebrate genomes"
        )
        
        sources['ncbi_eutils'] = ValidationSource(
            name="NCBI E-utilities",
            category=[QueryCategory.GENOMICS, QueryCategory.SCIENTIFIC_LITERATURE, QueryCategory.BIOLOGICAL_SEQUENCE],
            endpoint=self.credentials['services']['ncbi_eutilities']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.98,
            description="NCBI databases including PubMed, GenBank"
        )
        
        # Add chemistry sources
        sources['pubchem'] = ValidationSource(
            name="PubChem",
            category=[QueryCategory.CHEMISTRY],
            endpoint=self.credentials['services']['pubchem']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.95,
            description="Chemical compounds and bioassays"
        )
        
        # Add materials science sources
        sources['materials_project'] = ValidationSource(
            name="Materials Project",
            category=[QueryCategory.MATERIALS],
            endpoint=self.credentials['services']['materials_project']['endpoints']['base'],
            requires_auth=True,
            auth_key=self.credentials['services']['materials_project']['api_key'],
            confidence_weight=0.92,
            description="Computed materials properties"
        )
        
        sources['oqmd'] = ValidationSource(
            name="OQMD",
            category=[QueryCategory.MATERIALS],
            endpoint=self.credentials['services']['oqmd']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.90,
            description="Quantum materials database"
        )
        
        # Add ML/AI sources
        sources['openml'] = ValidationSource(
            name="OpenML",
            category=[QueryCategory.MACHINE_LEARNING, QueryCategory.DATA_SCIENCE],
            endpoint=self.credentials['services']['openml']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.88,
            description="ML datasets and experiments"
        )
        
        sources['huggingface'] = ValidationSource(
            name="Hugging Face",
            category=[QueryCategory.MACHINE_LEARNING, QueryCategory.GENERAL_AI],
            endpoint="https://huggingface.co/api",
            requires_auth=True,
            auth_key=self.credentials['services']['huggingface']['token'],
            confidence_weight=0.85,
            description="ML models and datasets"
        )
        
        # Add scientific literature sources
        sources['arxiv'] = ValidationSource(
            name="arXiv",
            category=[QueryCategory.SCIENTIFIC_LITERATURE, QueryCategory.PHYSICS, QueryCategory.MATHEMATICS],
            endpoint=self.credentials['services']['arxiv']['endpoints']['query'],
            requires_auth=False,
            confidence_weight=0.90,
            description="Preprint archive for sciences"
        )
        
        sources['pubmed'] = ValidationSource(
            name="PubMed Central",
            category=[QueryCategory.SCIENTIFIC_LITERATURE, QueryCategory.CLINICAL, QueryCategory.NEUROSCIENCE],
            endpoint="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
            requires_auth=False,
            confidence_weight=0.95,
            description="Biomedical literature"
        )
        
        # Add protein sequence sources
        sources['uniprot'] = ValidationSource(
            name="UniProt",
            category=[QueryCategory.BIOLOGICAL_SEQUENCE, QueryCategory.PROTEIN_STRUCTURE],
            endpoint=self.credentials['services']['uniprot']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.96,
            description="Protein sequence and function"
        )
        
        sources['blast'] = ValidationSource(
            name="BLAST",
            category=[QueryCategory.BIOLOGICAL_SEQUENCE],
            endpoint=self.credentials['services']['blast']['endpoints']['base'],
            requires_auth=False,
            confidence_weight=0.94,
            description="Sequence similarity search"
        )
        
        # Add computational sources
        sources['wolfram'] = ValidationSource(
            name="Wolfram Alpha",
            category=[QueryCategory.COMPUTATIONAL, QueryCategory.MATHEMATICS, QueryCategory.PHYSICS],
            endpoint="http://api.wolframalpha.com/v2/query",
            requires_auth=True,
            auth_key=self.credentials['services']['wolfram']['app_id'],
            confidence_weight=0.92,
            description="Computational knowledge engine"
        )
        
        # Add AI validation sources
        sources['openai'] = ValidationSource(
            name="OpenAI GPT",
            category=[QueryCategory.GENERAL_AI, QueryCategory.CODE_DOCUMENTATION],
            endpoint="https://api.openai.com/v1/chat/completions",
            requires_auth=True,
            auth_key=self.credentials['services']['openai']['api_key'],
            confidence_weight=0.80,
            description="General AI validation"
        )
        
        sources['claude'] = ValidationSource(
            name="Claude",
            category=[QueryCategory.GENERAL_AI, QueryCategory.CODE_DOCUMENTATION],
            endpoint="https://api.anthropic.com/v1/messages",
            requires_auth=True,
            auth_key=self.credentials['services']['claude']['api_key'],
            confidence_weight=0.82,
            description="Advanced reasoning validation"
        )
        
        sources['gemini'] = ValidationSource(
            name="Gemini",
            category=[QueryCategory.GENERAL_AI],
            endpoint="https://generativelanguage.googleapis.com/v1beta/models",
            requires_auth=True,
            auth_key=self.credentials['services']['gemini']['api_key'],
            confidence_weight=0.78,
            description="Google AI validation"
        )
        
        # Add code/documentation sources
        sources['context7'] = ValidationSource(
            name="Context7",
            category=[QueryCategory.CODE_DOCUMENTATION],
            endpoint="https://api.context7.ai/v1",
            requires_auth=True,
            auth_key=self.credentials['services']['context7']['api_key'],
            confidence_weight=0.85,
            description="Code documentation for libraries"
        )
        
        sources['github'] = ValidationSource(
            name="GitHub",
            category=[QueryCategory.CODE_DOCUMENTATION],
            endpoint="https://api.github.com",
            requires_auth=True,
            auth_key=self.credentials['services']['github']['token'],
            confidence_weight=0.88,
            description="Code repositories and documentation"
        )
        
        # Add data sources
        sources['kaggle'] = ValidationSource(
            name="Kaggle",
            category=[QueryCategory.DATA_SCIENCE, QueryCategory.MACHINE_LEARNING],
            endpoint="https://www.kaggle.com/api/v1",
            requires_auth=True,
            auth_key=self.credentials['services']['kaggle']['api_key'],
            confidence_weight=0.82,
            description="Datasets and ML competitions"
        )
        
        logger.info(f"‚úÖ Initialized {len(sources)} validation sources from credentials")
        return sources
    
    def categorize_query(self, query: str) -> List[QueryCategory]:
        """Intelligently categorize a query to determine best validation sources"""
        categories = []
        query_lower = query.lower()
        
        # Protein/structure keywords
        if any(kw in query_lower for kw in ['protein', 'structure', 'pdb', 'fold', 'domain', 'binding site']):
            categories.append(QueryCategory.PROTEIN_STRUCTURE)
        
        # Genomics keywords
        if any(kw in query_lower for kw in ['gene', 'genome', 'transcript', 'chromosome', 'variant', 'snp', 'mutation']):
            categories.append(QueryCategory.GENOMICS)
        
        # Neuroscience keywords
        if any(kw in query_lower for kw in ['brain', 'neuron', 'synapse', 'neural', 'cognitive', 'cortex']):
            categories.append(QueryCategory.NEUROSCIENCE)
        
        # Chemistry keywords
        if any(kw in query_lower for kw in ['compound', 'molecule', 'drug', 'chemical', 'reaction', 'inhibitor']):
            categories.append(QueryCategory.CHEMISTRY)
        
        # Materials keywords
        if any(kw in query_lower for kw in ['material', 'crystal', 'band gap', 'lattice', 'alloy', 'semiconductor']):
            categories.append(QueryCategory.MATERIALS)
        
        # ML keywords
        if any(kw in query_lower for kw in ['machine learning', 'ml', 'model', 'dataset', 'training', 'neural network']):
            categories.append(QueryCategory.MACHINE_LEARNING)
        
        # Literature keywords
        if any(kw in query_lower for kw in ['paper', 'publication', 'study', 'research', 'citation', 'reference']):
            categories.append(QueryCategory.SCIENTIFIC_LITERATURE)
        
        # Sequence keywords
        if any(kw in query_lower for kw in ['sequence', 'blast', 'alignment', 'homolog', 'ortholog', 'fasta']):
            categories.append(QueryCategory.BIOLOGICAL_SEQUENCE)
        
        # Clinical keywords
        if any(kw in query_lower for kw in ['disease', 'patient', 'clinical', 'therapy', 'treatment', 'diagnosis']):
            categories.append(QueryCategory.CLINICAL)
        
        # Computational keywords
        if any(kw in query_lower for kw in ['calculate', 'compute', 'equation', 'formula', 'algorithm']):
            categories.append(QueryCategory.COMPUTATIONAL)
        
        # Code keywords
        if any(kw in query_lower for kw in ['code', 'api', 'function', 'library', 'documentation', 'implement']):
            categories.append(QueryCategory.CODE_DOCUMENTATION)
        
        # Physics keywords
        if any(kw in query_lower for kw in ['physics', 'quantum', 'particle', 'energy', 'force', 'field']):
            categories.append(QueryCategory.PHYSICS)
        
        # Math keywords
        if any(kw in query_lower for kw in ['math', 'equation', 'theorem', 'proof', 'calculus', 'algebra']):
            categories.append(QueryCategory.MATHEMATICS)
        
        # Default to general AI if no specific category
        if not categories:
            categories.append(QueryCategory.GENERAL_AI)
        
        return categories
    
    def select_validation_sources(self, query: str, min_sources: int = 3) -> List[ValidationSource]:
        """
        Intelligently select the BEST sources for validating a query
        ALWAYS uses multiple sources for cross-validation
        """
        categories = self.categorize_query(query)
        selected_sources = []
        
        # First pass: get all sources matching categories
        for source_name, source in self.validation_sources.items():
            for category in categories:
                if category in source.category:
                    selected_sources.append(source)
                    break
        
        # Sort by confidence weight
        selected_sources.sort(key=lambda x: x.confidence_weight, reverse=True)
        
        # Ensure minimum number of sources
        if len(selected_sources) < min_sources:
            # Add high-confidence general sources
            general_sources = [
                self.validation_sources.get('arxiv'),
                self.validation_sources.get('pubmed'),
                self.validation_sources.get('openai'),
                self.validation_sources.get('claude')
            ]
            for source in general_sources:
                if source and source not in selected_sources:
                    selected_sources.append(source)
                if len(selected_sources) >= min_sources:
                    break
        
        logger.info(f"‚úÖ Selected {len(selected_sources)} sources for query: {categories}")
        return selected_sources[:10]  # Limit to top 10 sources
    
    async def validate_claim(self, claim: str, context: Optional[str] = None) -> Dict[str, Any]:
        """
        MANDATORY validation of a claim using ALL relevant sources
        Returns confidence score and evidence
        """
        # Create cache key
        cache_key = hashlib.md5(f"{claim}{context}".encode()).hexdigest()
        
        # Check cache
        if cache_key in self.validation_cache:
            logger.info(f"‚úÖ Using cached validation for claim: {claim[:50]}...")
            return self.validation_cache[cache_key]
        
        # Select appropriate sources
        sources = self.select_validation_sources(claim)
        
        # Validate against each source
        validations = []
        for source in sources:
            try:
                result = await self._validate_with_source(claim, context, source)
                validations.append(result)
            except Exception as e:
                logger.error(f"‚ùå Validation failed for {source.name}: {e}")
        
        # Aggregate results
        aggregate_result = self._aggregate_validations(validations)
        
        # Cache result
        self.validation_cache[cache_key] = aggregate_result
        
        # Log validation
        self.validation_history.append({
            'timestamp': datetime.now().isoformat(),
            'claim': claim,
            'sources_used': [s.name for s in sources],
            'confidence': aggregate_result['confidence'],
            'consensus': aggregate_result['consensus']
        })
        
        return aggregate_result
    
    async def _validate_with_source(self, claim: str, context: str, source: ValidationSource) -> Dict[str, Any]:
        """Validate claim with a specific source"""
        # This would implement actual API calls to each source
        # For now, returning a structure
        return {
            'source': source.name,
            'confidence': source.confidence_weight,
            'evidence': f"Validation from {source.name}",
            'supports_claim': True,
            'details': {}
        }
    
    def _aggregate_validations(self, validations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Aggregate multiple validation results"""
        if not validations:
            return {
                'confidence': 0.0,
                'consensus': 'NO_VALIDATION',
                'evidence': [],
                'sources_checked': 0
            }
        
        # Calculate weighted confidence
        total_weight = sum(v['confidence'] for v in validations)
        supporting = sum(1 for v in validations if v.get('supports_claim', False))
        
        confidence = (supporting / len(validations)) * (total_weight / len(validations))
        
        # Determine consensus
        if supporting == len(validations):
            consensus = 'STRONG_SUPPORT'
        elif supporting > len(validations) * 0.7:
            consensus = 'MODERATE_SUPPORT'
        elif supporting > len(validations) * 0.3:
            consensus = 'MIXED_EVIDENCE'
        else:
            consensus = 'CONTRADICTED'
        
        return {
            'confidence': min(confidence, 0.90),  # Cap at 90% per anti-overconfidence rules
            'consensus': consensus,
            'evidence': validations,
            'sources_checked': len(validations),
            'supporting_sources': supporting
        }
    
    def get_validation_report(self) -> Dict[str, Any]:
        """Generate comprehensive validation report"""
        return {
            'total_sources_available': len(self.validation_sources),
            'sources_by_category': self._count_sources_by_category(),
            'validation_history_count': len(self.validation_history),
            'cache_size': len(self.validation_cache),
            'credentials_loaded': len(self.credentials.get('services', {})),
            'knowledge_sources_loaded': self.knowledge_sources.get('metadata', {}).get('total_sources', 0)
        }
    
    def _count_sources_by_category(self) -> Dict[str, int]:
        """Count sources by category"""
        category_counts = {}
        for source in self.validation_sources.values():
            for category in source.category:
                category_counts[category.value] = category_counts.get(category.value, 0) + 1
        return category_counts
    
    def mandatory_validation_check(self, statement: str) -> Tuple[bool, str]:
        """
        MANDATORY check that MUST be called before making any claim
        Returns (is_validated, validation_message)
        """
        # This would be called by the anti-overconfidence system
        sources = self.select_validation_sources(statement)
        
        if len(sources) < 3:
            return False, f"‚ùå INSUFFICIENT SOURCES: Only {len(sources)} sources available for validation"
        
        validation_message = f"""
‚ö†Ô∏è MANDATORY VALIDATION REQUIRED
Statement: {statement[:100]}...
Selected Sources: {', '.join(s.name for s in sources[:5])}
Categories: {', '.join(c.value for c in self.categorize_query(statement))}

This statement MUST be validated against authoritative sources before proceeding.
"""
        return True, validation_message
    
    def get_all_available_sources(self) -> List[str]:
        """Return list of ALL available validation sources"""
        return list(self.validation_sources.keys())
    
    def verify_all_sources_active(self) -> Dict[str, bool]:
        """Verify that ALL sources are properly configured"""
        status = {}
        for name, source in self.validation_sources.items():
            if source.requires_auth:
                status[name] = bool(source.auth_key)
            else:
                status[name] = True
        
        inactive = [k for k, v in status.items() if not v]
        if inactive:
            logger.warning(f"‚ö†Ô∏è Inactive sources: {inactive}")
        else:
            logger.info(f"‚úÖ All {len(status)} validation sources are active")
        
        return status


# Singleton instance
_validation_system = None

def get_validation_system() -> ComprehensiveValidationSystem:
    """Get or create the singleton validation system"""
    global _validation_system
    if _validation_system is None:
        _validation_system = ComprehensiveValidationSystem()
    return _validation_system

def mandatory_validate(claim: str, context: str = None) -> Dict[str, Any]:
    """
    MANDATORY validation function that MUST be called
    Uses ALL available resources intelligently
    """
    system = get_validation_system()
    
    # Run async validation
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        result = loop.run_until_complete(system.validate_claim(claim, context))
    finally:
        loop.close()
    
    # Log validation
    logger.info(f"""
üìä VALIDATION COMPLETE:
Claim: {claim[:100]}...
Confidence: {result['confidence']*100:.1f}%
Consensus: {result['consensus']}
Sources: {result['sources_checked']}
""")
    
    return result

if __name__ == "__main__":
    # Test the system
    system = get_validation_system()
    
    print("üîç COMPREHENSIVE VALIDATION SYSTEM INITIALIZED")
    print(f"‚úÖ Total Sources Available: {len(system.get_all_available_sources())}")
    print(f"‚úÖ Sources: {', '.join(system.get_all_available_sources())}")
    
    # Verify all sources
    status = system.verify_all_sources_active()
    active_count = sum(1 for v in status.values() if v)
    print(f"‚úÖ Active Sources: {active_count}/{len(status)}")
    
    # Generate report
    report = system.get_validation_report()
    print(f"""
üìä VALIDATION SYSTEM REPORT:
- Total Sources: {report['total_sources_available']}
- Credentials Loaded: {report['credentials_loaded']}
- Knowledge Sources: {report['knowledge_sources_loaded']}
- Categories Covered: {len(report['sources_by_category'])}
""")
    
    # Test validation
    test_claims = [
        "AlphaFold can predict protein structures",
        "Neural networks in the brain use backpropagation",
        "CRISPR can edit any gene with 100% accuracy"
    ]
    
    for claim in test_claims:
        is_valid, message = system.mandatory_validation_check(claim)
        print(f"\nüìå Claim: {claim}")
        print(message)
